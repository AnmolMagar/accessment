{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3eb4c2a3",
   "metadata": {},
   "source": [
    "# Final Portfolio Project - Regression Task\n",
    "\n",
    "# Weather Temperature Prediction (Regression)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19aeb6fd",
   "metadata": {},
   "source": [
    "## Task 1: Exploratory Data Analysis and Data Understanding [20 Marks]\n",
    "\n",
    "### 1.1 Choosing a Dataset\n",
    "\n",
    "#### (a) When and by whom the dataset was created\n",
    "Provide the dataset provenance here (creator/owner and year, if known).\n",
    "\n",
    "#### (b) How and from where the dataset was accessed\n",
    "Provide the dataset source here (website / repository / provider) and the access date.\n",
    "\n",
    "#### (c) Alignment with United Nations Sustainable Development Goal (UNSDG)\n",
    "This dataset relates to **SDG 13: Climate Action** and **SDG 11: Sustainable Cities and Communities** because weather conditions and temperature patterns are important for planning, resilience, and climate-informed decision making.\n",
    "\n",
    "#### (d) List all attributes (columns) with brief descriptions\n",
    "Use the column list table (next code cell) to write brief descriptions of each attribute in your report.\n",
    "\n",
    "#### Potential Questions the Dataset Can Answer\n",
    "1. How do humidity, wind speed, and pressure relate to temperature?\n",
    "2. Are there seasonal patterns in temperature across months?\n",
    "3. How accurately can temperature be predicted from the available meteorological variables?\n",
    "\n",
    "#### Dataset Quality Assessment\n",
    "The next cells check missing values, duplicates, and basic statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70387650",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Preprocessing / Model selection\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Metrics\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    confusion_matrix, ConfusionMatrixDisplay,\n",
    "    mean_absolute_error, mean_squared_error, r2_score\n",
    ")\n",
    "\n",
    "# Models\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.neural_network import MLPClassifier, MLPRegressor\n",
    "\n",
    "# Feature selection\n",
    "from sklearn.feature_selection import SelectKBest, mutual_info_classif, mutual_info_regression\n",
    "\n",
    "# Reproducibility\n",
    "RANDOM_STATE = 42\n",
    "np.random.seed(RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3721a9bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "try:\n",
    "    df = pd.read_csv(\"weatherHistory.csv\")\n",
    "except FileNotFoundError:\n",
    "    df = pd.read_csv(\"/mnt/data/weatherHistory.csv\")\n",
    "\n",
    "print(\"Shape:\", df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efb0a3e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Column list\n",
    "pd.DataFrame({\"column\": df.columns, \"dtype\": [str(df[c].dtype) for c in df.columns]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca4ff674",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Missing values and duplicates\n",
    "missing = df.isna().sum().sort_values(ascending=False)\n",
    "print(\"Missing values (top):\")\n",
    "display(missing[missing>0].head(20))\n",
    "\n",
    "print(\"\\nDuplicate rows:\", df.duplicated().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c83396c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary statistics for numeric columns\n",
    "df.describe(include=[np.number]).T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbcef2dc",
   "metadata": {},
   "source": [
    "### 1.2 Exploratory Data Analysis (EDA)\n",
    "\n",
    "#### (a) Data Cleaning and Preprocessing\n",
    "\n",
    "We predict **Temperature (C)** as the target. The date column is parsed to extract time-based features. Categorical columns are one-hot encoded; numeric columns are imputed and scaled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aa56fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse datetime and create time features\n",
    "df = df.copy()\n",
    "\n",
    "df[\"Formatted Date\"] = pd.to_datetime(df[\"Formatted Date\"], errors=\"coerce\", utc=True)\n",
    "\n",
    "df[\"year\"] = df[\"Formatted Date\"].dt.year\n",
    "df[\"month\"] = df[\"Formatted Date\"].dt.month\n",
    "df[\"day\"] = df[\"Formatted Date\"].dt.day\n",
    "df[\"hour\"] = df[\"Formatted Date\"].dt.hour\n",
    "\n",
    "# Drop original datetime after feature extraction\n",
    "df = df.drop(columns=[\"Formatted Date\"])\n",
    "\n",
    "# Ensure numeric columns are numeric\n",
    "for col in [\"Temperature (C)\", \"Apparent Temperature (C)\", \"Humidity\", \"Wind Speed (km/h)\",\n",
    "            \"Wind Bearing (degrees)\", \"Visibility (km)\", \"Loud Cover\", \"Pressure (millibars)\"]:\n",
    "    if col in df.columns:\n",
    "        df[col] = pd.to_numeric(df[col], errors=\"coerce\")\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b8a7422",
   "metadata": {},
   "source": [
    "#### (b) Visualizations to Summarize, Explore, and Understand the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a089f4bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of target temperature\n",
    "plt.figure(figsize=(7,4))\n",
    "sns.histplot(df[\"Temperature (C)\"].dropna(), kde=True)\n",
    "plt.title(\"Distribution of Temperature (C)\")\n",
    "plt.xlabel(\"Temperature (C)\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b496fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Temperature vs humidity\n",
    "plt.figure(figsize=(7,5))\n",
    "sns.scatterplot(data=df.sample(5000, random_state=RANDOM_STATE), x=\"Humidity\", y=\"Temperature (C)\", alpha=0.4)\n",
    "plt.title(\"Temperature vs Humidity (sample)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "946ae2f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation heatmap for numeric features\n",
    "num_cols = [c for c in df.columns if df[c].dtype != \"object\"]\n",
    "corr = df[num_cols].corr()\n",
    "\n",
    "plt.figure(figsize=(10,7))\n",
    "sns.heatmap(corr, cmap=\"coolwarm\", center=0)\n",
    "plt.title(\"Correlation Heatmap (Numeric Features)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f53ac43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average temperature by month\n",
    "if \"month\" in df.columns:\n",
    "    month_avg = df.groupby(\"month\")[\"Temperature (C)\"].mean()\n",
    "    month_avg.plot(kind=\"line\", marker=\"o\")\n",
    "    plt.title(\"Average Temperature by Month\")\n",
    "    plt.xlabel(\"Month\")\n",
    "    plt.ylabel(\"Avg Temperature (C)\")\n",
    "    plt.show()\n",
    "\n",
    "month_avg.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7acff95",
   "metadata": {},
   "source": [
    "#### (c) Summary of EDA Insights\n",
    "\n",
    "Summarize key patterns observed in the plots (e.g., seasonal trend by month, correlation with apparent temperature, etc.)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc34d2bb",
   "metadata": {},
   "source": [
    "## Task 2: Build a Neural Network Model for Regression [15 Marks]\n",
    "\n",
    "We use an MLPRegressor with a preprocessing pipeline (imputation + one-hot encoding + scaling)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2925de40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target and features\n",
    "target = \"Temperature (C)\"\n",
    "X = df.drop(columns=[target])\n",
    "y = df[target]\n",
    "\n",
    "# Train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "# Column types\n",
    "numeric_features = [c for c in X_train.columns if X_train[c].dtype != \"object\"]\n",
    "categorical_features = [c for c in X_train.columns if X_train[c].dtype == \"object\"]\n",
    "\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"scaler\", StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "    (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
    "])\n",
    "\n",
    "preprocess = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numeric_transformer, numeric_features),\n",
    "        (\"cat\", categorical_transformer, categorical_features)\n",
    "    ]\n",
    ")\n",
    "\n",
    "mlp_reg = MLPRegressor(\n",
    "    hidden_layer_sizes=(64, 32),\n",
    "    activation=\"relu\",\n",
    "    solver=\"adam\",\n",
    "    alpha=1e-4,\n",
    "    max_iter=300,\n",
    "    random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "mlp_pipe = Pipeline(steps=[\n",
    "    (\"preprocess\", preprocess),\n",
    "    (\"model\", mlp_reg)\n",
    "])\n",
    "\n",
    "mlp_pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f7b832a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train neural network regressor\n",
    "mlp_pipe.fit(X_train, y_train)\n",
    "\n",
    "pred_train = mlp_pipe.predict(X_train)\n",
    "pred_test = mlp_pipe.predict(X_test)\n",
    "\n",
    "def reg_metrics(y_true, y_pred, label=\"\"):\n",
    "    rmse = mean_squared_error(y_true, y_pred, squared=False)\n",
    "    return pd.Series({\n",
    "        \"MAE\": mean_absolute_error(y_true, y_pred),\n",
    "        \"MSE\": mean_squared_error(y_true, y_pred),\n",
    "        \"RMSE\": rmse,\n",
    "        \"R2\": r2_score(y_true, y_pred)\n",
    "    }, name=label)\n",
    "\n",
    "metrics_train = reg_metrics(y_train, pred_train, \"Train\")\n",
    "metrics_test = reg_metrics(y_test, pred_test, \"Test\")\n",
    "\n",
    "pd.concat([metrics_train, metrics_test], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ef706af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicted vs actual (sample)\n",
    "sample_idx = np.random.RandomState(RANDOM_STATE).choice(len(y_test), size=2000, replace=False)\n",
    "plt.figure(figsize=(6,6))\n",
    "plt.scatter(y_test.iloc[sample_idx], pred_test[sample_idx], alpha=0.3)\n",
    "plt.xlabel(\"Actual Temperature (C)\")\n",
    "plt.ylabel(\"Predicted Temperature (C)\")\n",
    "plt.title(\"MLPRegressor: Actual vs Predicted (sample)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "234a74d8",
   "metadata": {},
   "source": [
    "## Task 3: Build Primary Machine Learning Models [20 Marks] (Two Classical ML Models)\n",
    "\n",
    "### 3.1 Split Dataset into Training and Testing Sets\n",
    "\n",
    "The same split from Task 2 is used.\n",
    "\n",
    "### 3.2 Model A: Linear Regression\n",
    "### 3.3 Model B: Random Forest Regressor\n",
    "### 3.4 Initial Comparison and Discussion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aa8fb1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model A: Linear Regression\n",
    "lin_reg = LinearRegression()\n",
    "\n",
    "linreg_pipe = Pipeline(steps=[\n",
    "    (\"preprocess\", preprocess),\n",
    "    (\"model\", lin_reg)\n",
    "])\n",
    "\n",
    "linreg_pipe.fit(X_train, y_train)\n",
    "pred_lr = linreg_pipe.predict(X_test)\n",
    "\n",
    "lr_metrics = reg_metrics(y_test, pred_lr, \"Linear Regression\")\n",
    "lr_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50e4ec72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model B: Random Forest Regressor\n",
    "rf_reg = RandomForestRegressor(\n",
    "    n_estimators=300,\n",
    "    random_state=RANDOM_STATE,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "rf_pipe = Pipeline(steps=[\n",
    "    (\"preprocess\", preprocess),\n",
    "    (\"model\", rf_reg)\n",
    "])\n",
    "\n",
    "rf_pipe.fit(X_train, y_train)\n",
    "pred_rf = rf_pipe.predict(X_test)\n",
    "\n",
    "rf_metrics = reg_metrics(y_test, pred_rf, \"Random Forest\")\n",
    "rf_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fbdba62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial comparison (test set)\n",
    "initial_comp = pd.DataFrame([lr_metrics, rf_metrics]).reset_index().rename(columns={\"index\":\"Model\"})\n",
    "initial_comp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef87b3f7",
   "metadata": {},
   "source": [
    "## Task 4: Hyperparameter Optimization with Cross-Validation [15 Marks]\n",
    "\n",
    "We tune the two classical regression models with cross-validation.\n",
    "\n",
    "- Linear Regression has fewer hyperparameters; we tune whether to fit the intercept and use feature selection with k.\n",
    "- Random Forest has key hyperparameters such as max_depth and min_samples_leaf.\n",
    "\n",
    "CV scoring uses **negative RMSE**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93a75f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.1 Linear Regression tuning (including SelectKBest as part of pipeline)\n",
    "neg_rmse = \"neg_root_mean_squared_error\"\n",
    "\n",
    "k_best = 30\n",
    "\n",
    "linreg_tune_pipe = Pipeline(steps=[\n",
    "    (\"preprocess\", preprocess),\n",
    "    (\"select\", SelectKBest(score_func=mutual_info_regression, k=k_best)),\n",
    "    (\"model\", LinearRegression())\n",
    "])\n",
    "\n",
    "linreg_param_grid = {\n",
    "    \"model__fit_intercept\": [True, False],\n",
    "}\n",
    "\n",
    "linreg_gs = GridSearchCV(\n",
    "    linreg_tune_pipe,\n",
    "    param_grid=linreg_param_grid,\n",
    "    scoring=neg_rmse,\n",
    "    cv=5,\n",
    "    n_jobs=-1\n",
    ")\n",
    "linreg_gs.fit(X_train, y_train)\n",
    "\n",
    "linreg_gs.best_params_, linreg_gs.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22b38072",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.2 Random Forest tuning\n",
    "rf_tune_pipe = Pipeline(steps=[\n",
    "    (\"preprocess\", preprocess),\n",
    "    (\"select\", SelectKBest(score_func=mutual_info_regression, k=k_best)),\n",
    "    (\"model\", RandomForestRegressor(random_state=RANDOM_STATE, n_jobs=-1))\n",
    "])\n",
    "\n",
    "rf_param_grid = {\n",
    "    \"model__n_estimators\": [200, 400],\n",
    "    \"model__max_depth\": [None, 10, 20],\n",
    "    \"model__min_samples_split\": [2, 5],\n",
    "    \"model__min_samples_leaf\": [1, 2]\n",
    "}\n",
    "\n",
    "rf_gs = GridSearchCV(\n",
    "    rf_tune_pipe,\n",
    "    param_grid=rf_param_grid,\n",
    "    scoring=neg_rmse,\n",
    "    cv=5,\n",
    "    n_jobs=-1\n",
    ")\n",
    "rf_gs.fit(X_train, y_train)\n",
    "\n",
    "rf_gs.best_params_, rf_gs.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78dff9fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.3 Summary of Best Hyperparameters and CV scores\n",
    "pd.DataFrame([\n",
    "    {\"Model\": \"Linear Regression\", \"Best CV Score (neg RMSE)\": linreg_gs.best_score_, \"Best Params\": linreg_gs.best_params_},\n",
    "    {\"Model\": \"Random Forest\", \"Best CV Score (neg RMSE)\": rf_gs.best_score_, \"Best Params\": rf_gs.best_params_},\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c936fc4e",
   "metadata": {},
   "source": [
    "## Task 5: Feature Selection [10 Marks]\n",
    "\n",
    "A filter method is applied using mutual information after preprocessing with SelectKBest. This is applied for both classical regression models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7610cd9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate feature selection impact via CV (neg RMSE)\n",
    "fs_linreg_cv = cross_val_score(linreg_tune_pipe, X_train, y_train, cv=5, scoring=neg_rmse, n_jobs=-1).mean()\n",
    "fs_rf_cv = cross_val_score(rf_tune_pipe, X_train, y_train, cv=5, scoring=neg_rmse, n_jobs=-1).mean()\n",
    "\n",
    "fs_linreg_cv, fs_rf_cv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f40d4f78",
   "metadata": {},
   "source": [
    "## Task 6: Final Models and Comparative Analysis [10 Marks]\n",
    "\n",
    "Rebuild both models using:\n",
    "- Best hyperparameters from Task 4\n",
    "- Selected features from Task 5\n",
    "\n",
    "Evaluate on the test set and compare."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "469493a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final models (already include SelectKBest)\n",
    "\n",
    "final_linreg = linreg_gs.best_estimator_\n",
    "final_rf = rf_gs.best_estimator_\n",
    "\n",
    "final_linreg.fit(X_train, y_train)\n",
    "final_rf.fit(X_train, y_train)\n",
    "\n",
    "pred_linreg = final_linreg.predict(X_test)\n",
    "pred_rf = final_rf.predict(X_test)\n",
    "\n",
    "final_lr_metrics = reg_metrics(y_test, pred_linreg, \"Final Linear Regression\")\n",
    "final_rf_metrics = reg_metrics(y_test, pred_rf, \"Final Random Forest\")\n",
    "\n",
    "final_lr_metrics, final_rf_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24cdbc25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparison table (similar to Table 2 / Table 5 in the assignment)\n",
    "comparison_table = pd.DataFrame([\n",
    "    {\n",
    "        \"Model\": \"Linear Regression (Final)\",\n",
    "        \"Features Used\": f\"SelectKBest(k={k_best})\",\n",
    "        \"CV Score (neg RMSE)\": linreg_gs.best_score_,\n",
    "        \"Test MAE\": final_lr_metrics[\"MAE\"],\n",
    "        \"Test RMSE\": final_lr_metrics[\"RMSE\"],\n",
    "        \"Test R2\": final_lr_metrics[\"R2\"],\n",
    "    },\n",
    "    {\n",
    "        \"Model\": \"Random Forest (Final)\",\n",
    "        \"Features Used\": f\"SelectKBest(k={k_best})\",\n",
    "        \"CV Score (neg RMSE)\": rf_gs.best_score_,\n",
    "        \"Test MAE\": final_rf_metrics[\"MAE\"],\n",
    "        \"Test RMSE\": final_rf_metrics[\"RMSE\"],\n",
    "        \"Test R2\": final_rf_metrics[\"R2\"],\n",
    "    },\n",
    "])\n",
    "\n",
    "comparison_table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69693bcc",
   "metadata": {},
   "source": [
    "## Task 7: Report Quality and Presentation [5 Marks]\n",
    "\n",
    "- Code is organized into tasks and uses pipelines for reproducibility.\n",
    "- Visualizations are labeled clearly.\n",
    "- Tables summarize results for comparison.\n",
    "\n",
    "## Task 8: Conclusion and Reflection [5 Marks]\n",
    "\n",
    "1. **Model Performance:** Discuss which final model performed best and why (use MAE/RMSE/R2).\n",
    "2. **Impact of Methods:** Explain how cross-validation tuning and feature selection affected performance.\n",
    "3. **Insights and Future Directions:** State key insights from EDA/modeling and suggest improvements (e.g., feature engineering, trying other models)."
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
